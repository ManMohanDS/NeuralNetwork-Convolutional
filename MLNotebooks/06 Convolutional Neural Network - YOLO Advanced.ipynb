{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network - YOLO Advanced\n",
    "Real Time Camera Prediction\n",
    "Video Predcition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda, Conv2D\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "import colorsys\n",
    "import random\n",
    "\n",
    "import PIL as pil\n",
    "from PIL import ImageDraw,ImageFont,Image\n",
    "import imageio\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_classes(classes_path):\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def read_anchors(anchors_path):\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        anchors = np.array(anchors).reshape(-1, 2)\n",
    "    return anchors\n",
    "\n",
    "def yolo_head(feats, anchors, num_classes):   \n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = K.reshape(K.variable(anchors), [1, 1, 1, num_anchors, 2])\n",
    "\n",
    "    # Dynamic implementation of conv dims for fully convolutional model.\n",
    "    conv_dims = K.shape(feats)[1:3]  # assuming channels last\n",
    "\n",
    "    # In YOLO the height index is the inner most iteration.\n",
    "    conv_height_index = K.arange(0, stop=conv_dims[0])\n",
    "    conv_width_index = K.arange(0, stop=conv_dims[1])\n",
    "    conv_height_index = K.tile(conv_height_index, [conv_dims[1]])\n",
    "\n",
    "    # conv_width_index = K.repeat_elements(conv_width_index, conv_dims[1], axis=0)\n",
    "\n",
    "    conv_width_index = K.tile(K.expand_dims(conv_width_index, 0), [conv_dims[0], 1])\n",
    "    conv_width_index = K.flatten(K.transpose(conv_width_index))\n",
    "    conv_index = K.transpose(K.stack([conv_height_index, conv_width_index]))\n",
    "    conv_index = K.reshape(conv_index, [1, conv_dims[0], conv_dims[1], 1, 2])\n",
    "\n",
    "    conv_index = K.cast(conv_index, dtype='float32')\n",
    "    feats = K.reshape(feats, [-1, conv_dims[0], conv_dims[1], num_anchors, num_classes + 5])\n",
    "    conv_dims = K.cast(K.reshape(conv_dims, [1, 1, 1, 1, 2]), K.dtype(feats))\n",
    "\n",
    "    box_xy = K.sigmoid(feats[..., :2])\n",
    "    box_wh = K.exp(feats[..., 2:4])\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_class_probs = K.softmax(feats[..., 5:])\n",
    "\n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    # Note: YOLO iterates over height index before width index.\n",
    "\n",
    "    box_xy = (box_xy + conv_index) / conv_dims\n",
    "    box_wh = box_wh * anchors_tensor / conv_dims\n",
    "\n",
    "    return box_confidence,box_xy, box_wh,  box_class_probs\n",
    "\n",
    "def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = .6):\n",
    "    # Step 1: Compute box scores\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    \n",
    "    # Step 2: Find the box_classes thanks to the max box_scores, keep track of the corresponding score\n",
    "    box_classes = K.argmax(box_scores, axis = -1)\n",
    "    box_class_scores = K.max(box_scores, axis = -1)\n",
    "    \n",
    "    # Step 3: Create a filtering mask based on \"box_class_scores\" by using \"threshold\". The mask should have the\n",
    "    # same dimension as box_class_scores, and be True for the boxes you want to keep (with probability >= threshold)\n",
    "    filtering_mask = (box_class_scores >= threshold)\n",
    "    \n",
    "    # Step 4: Apply the mask to scores, boxes and classes\n",
    "    scores = tf.boolean_mask(box_class_scores, filtering_mask)\n",
    "    boxes = tf.boolean_mask(boxes, filtering_mask)\n",
    "    classes = tf.boolean_mask(box_classes, filtering_mask)\n",
    "    \n",
    "    return scores, boxes, classes\n",
    "\n",
    "def iou(box1, box2):\n",
    "    # Calculate the (y1, x1, y2, x2) coordinates of the intersection of box1 and box2. Calculate its Area.\n",
    "    xi1 = np.maximum(box1[0], box2[0])\n",
    "    yi1 = np.maximum(box1[1], box2[1])\n",
    "    xi2 = np.minimum(box1[2], box2[2])\n",
    "    yi2 = np.minimum(box1[3], box2[3])\n",
    "    inter_area = np.abs((xi1 - xi2) * (yi1 - yi2))\n",
    "\n",
    "    # Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)\n",
    "    box1_area = np.abs((box1[2] - box1[0]) * (box1[3] - box1[1]))\n",
    "    box2_area = np.abs((box2[2] - box2[0]) * (box2[3] - box2[1]))\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "   \n",
    "    # compute the IoU\n",
    "    iou = inter_area / union_area\n",
    "\n",
    "    return iou\n",
    "\n",
    "def yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5): \n",
    "    max_boxes_tensor = K.variable(max_boxes, dtype='int32')     # tensor to be used in tf.image.non_max_suppression()\n",
    "    K.get_session().run(tf.variables_initializer([max_boxes_tensor])) # initialize variable max_boxes_tensor\n",
    "    \n",
    "    nms_indices = tf.image.non_max_suppression( boxes, scores, max_boxes_tensor, iou_threshold, name=None)\n",
    "    scores = K.gather(scores, nms_indices)\n",
    "    boxes = K.gather(boxes, nms_indices)\n",
    "    classes = K.gather(classes, nms_indices)\n",
    "    \n",
    "    return scores, boxes, classes\n",
    "\n",
    "def yolo_boxes_to_corners(box_xy, box_wh):    \n",
    "    box_mins = box_xy - (box_wh / 2.)\n",
    "    box_maxes = box_xy + (box_wh / 2.)\n",
    "\n",
    "    return K.concatenate([\n",
    "        box_mins[..., 1:2],  # y_min\n",
    "        box_mins[..., 0:1],  # x_min\n",
    "        box_maxes[..., 1:2],  # y_max\n",
    "        box_maxes[..., 0:1]  # x_max\n",
    "    ])\n",
    "\n",
    "def scale_boxes(boxes, image_shape):    \n",
    "    height = image_shape[0]\n",
    "    width = image_shape[1]\n",
    "    image_dims = K.stack([height, width, height, width])\n",
    "    image_dims = K.reshape(image_dims, [1, 4])\n",
    "    boxes = boxes * image_dims\n",
    "    return boxes\n",
    "\n",
    "def yolo_eval(yolo_outputs, image_shape = (720., 1280.), max_boxes=10,score_threshold=.6, iou_threshold=.5):    \n",
    "    # Retrieve outputs of the YOLO model\n",
    "    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs\n",
    "\n",
    "    # Convert boxes to be ready for filtering functions \n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "\n",
    "    # Use one of the functions you've implemented to perform Score-filtering with a threshold of score_threshold\n",
    "    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, score_threshold)\n",
    "    \n",
    "    # Scale boxes back to original image shape.\n",
    "    boxes = scale_boxes(boxes, image_shape)\n",
    "\n",
    "    # Use one of the functions you've implemented to perform Non-max suppression with a threshold of iou_threshold \n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold)\n",
    "        \n",
    "    return scores, boxes, classes\n",
    "\n",
    "def generate_colors(class_names):\n",
    "    hsv_tuples = [(x / len(class_names), 1., 1.) for x in range(len(class_names))]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "    random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "    random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "    random.seed(None)  # Reset seed to default.\n",
    "    return colors\n",
    "\n",
    "####################################################################################\n",
    "def draw_boxes(image, out_scores, out_boxes, out_classes, class_names, \n",
    "               colors,displayPredictionSummary=False):  \n",
    "    \n",
    "    fontSize=np.floor(3e-2 * image.size[1] + 0.5).astype('int32')\n",
    "    font = pil.ImageFont.truetype(font='arial.ttf',size=fontSize)\n",
    "    thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "        predicted_class = class_names[c]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "\n",
    "        label = '       {} {:.2f}'.format(predicted_class, score)\n",
    "\n",
    "        draw = pil.ImageDraw.Draw(image)\n",
    "        label_size = draw.textsize(label,font)\n",
    "\n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "        if(displayPredictionSummary):\n",
    "            print(label, (left, top), (right, bottom))\n",
    "\n",
    "        if top - label_size[1] >= 0:\n",
    "            text_origin = np.array([left, top - label_size[1]])\n",
    "        else:\n",
    "            text_origin = np.array([left, top + 1])\n",
    "\n",
    "        for i in range(thickness):\n",
    "            draw.rectangle([left + i, top + i, right - i, bottom - i], outline=colors[c])\n",
    "        draw.rectangle([tuple(text_origin), tuple(text_origin + label_size)], fill=colors[c])\n",
    "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "        del draw\n",
    "\n",
    "        \n",
    "def preprocess_image(img_path, model_image_size):\n",
    "    image = pil.Image.open(img_path)\n",
    "    resized_image = image.resize(tuple(reversed(model_image_size)), pil.Image.BICUBIC)\n",
    "    image_data = np.array(resized_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "    return image, image_data\n",
    "\n",
    "\n",
    "def CreateDirRecursive(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if(directory!=\"\"):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "def PredictImage(Sess, img,skipPrediction=False,out_scores=None,out_boxes=None, out_classes=None):\n",
    "    #CV2 to PIL Format\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    image = pil.Image.fromarray(img)\n",
    "    \n",
    "    \n",
    "    model_image_size = (608, 608)\n",
    "    resized_image = image.resize(tuple(reversed(model_image_size)), pil.Image.BICUBIC)\n",
    "    image_data = np.array(resized_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "    \n",
    "    \n",
    "    # Run the session with the correct tensors and placeholders in the feed_dict.\n",
    "    if(skipPrediction==False):\n",
    "        out_scores,out_boxes, out_classes = sess.run([scores, boxes, classes],\n",
    "                                                     feed_dict = {yolo_model.input:image_data,\n",
    "                                                                  K.learning_phase():0})\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    colors = generate_colors(class_names)\n",
    "    \n",
    "    # Draw bounding boxes on the image file\n",
    "    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)\n",
    "    \n",
    "    #PIL to cv2 \n",
    "    image = np.asarray(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return image,out_scores,out_boxes, out_classes\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def PredictFile(Sess, inputFileName,outputFileName=\"outputImage.jpg\",\n",
    "            displayPredictionSummary=False):\n",
    "    \n",
    "    # Preprocess your image\n",
    "    image, image_data = preprocess_image(inputFileName, model_image_size = (608, 608))\n",
    "\n",
    "    # Run the session with the correct tensors and placeholders in the feed_dict.\n",
    "    out_scores,out_boxes, out_classes = sess.run([scores, boxes, classes], \n",
    "                                                  feed_dict = {yolo_model.input:image_data, \n",
    "                                                               K.learning_phase():0})\n",
    "    \n",
    "   \n",
    "    # Print predictions info\n",
    "    if(displayPredictionSummary):\n",
    "        print('Found {} boxes for {}'.format(len(out_boxes), inputFileName))\n",
    "    \n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    colors = generate_colors(class_names)\n",
    "    \n",
    "    # Draw bounding boxes on the image file\n",
    "    draw_boxes(image, out_scores, out_boxes, out_classes, \n",
    "               class_names, colors,displayPredictionSummary)\n",
    "    \n",
    "    # Save the predicted bounding box on the image\n",
    "    \n",
    "    CreateDirRecursive(outputFileName)\n",
    "    image.save(outputFileName, quality=50)\n",
    "    \n",
    "    \n",
    "    return outputFileName\n",
    "def DisplayImage(imgFileName,style=\"popup\"):\n",
    "    winName='Image'\n",
    "    img = cv2.imread(imgFileName)\n",
    "    img = cv2.resize(img, dsize=(800,500))\n",
    "    if(style.lower()==\"popup\"):\n",
    "        while True:\n",
    "            cv2.imshow(winName, img)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            if cv2.getWindowProperty(winName,1) == -1 :\n",
    "                break\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "sess = K.get_session()\n",
    "class_names = read_classes(\"../Input/YoloDS/model_data/coco_classes.txt\")\n",
    "anchors = read_anchors(\"../Input/YoloDS/model_data/yolo_anchors.txt\")\n",
    "image_shape = (720., 1280.)    \n",
    "yolo_model = load_model(\"../Input/YoloDS/model_data/yolo.h5\")\n",
    "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))\n",
    "scores, boxes, classes = yolo_eval(yolo_outputs, image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-895d68dda4ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minputFileName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"../Input/YoloDS/images/test1.jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moutputFileName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputFileName\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Output\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moutputFileName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputFileName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputFileName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mDisplayImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputFileName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"popup\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Predict' is not defined"
     ]
    }
   ],
   "source": [
    "inputFileName=\"../Input/YoloDS/images/test1.jpg\"\n",
    "outputFileName=inputFileName.replace(\"Input\",\"Output\")\n",
    "outputFileName=Predict(sess,inputFileName,outputFileName,True)\n",
    "DisplayImage(outputFileName,\"popup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "FolderPath=\"../Input/YoloDS/images/RoadDrive\"\n",
    "imgIndex=0\n",
    "winName='Test Drive'\n",
    "imgList=glob.glob(FolderPath+\"/*.jpg\")\n",
    "skipPrediction=False\n",
    "out_scores=None\n",
    "out_boxes=None\n",
    "out_classes=None\n",
    "\n",
    "while True:\n",
    "    if (imgIndex>len(imgList)-1):\n",
    "        imgIndex=0\n",
    "    inputFileName=imgList[imgIndex]\n",
    "    outputFileName=inputFileName.replace(\"Input\",\"Output\")\n",
    "    PredictFile(sess,inputFileName,outputFileName)\n",
    "    imgIndex=imgIndex+1\n",
    "    img = cv2.imread(outputFileName)\n",
    "    img=cv2.resize(img, dsize=(800,500))\n",
    "    cv2.imshow(winName, img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    if cv2.getWindowProperty(winName,1) == -1 :\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'video_capture' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fe387c91f848>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mvideo_capture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'video_capture' is not defined"
     ]
    }
   ],
   "source": [
    "vFileName='../input/YoloDS/Videos/BMW Vision Self Driving Car.mp4'\n",
    "winName='BMW Vision Self Driving Car.mp4'\n",
    "vidcap = cv2.VideoCapture(vFileName)\n",
    "success,img = vidcap.read()\n",
    "success = True\n",
    "count=0\n",
    "skipPrediction=False\n",
    "out_scores=None\n",
    "out_boxes=None\n",
    "out_classes=None\n",
    "\n",
    "while success:\n",
    "    if (count%10!=0):  \n",
    "        skipPrediction=True\n",
    "    else:\n",
    "        skipPrediction=False\n",
    "    img,out_scores,out_boxes,out_classes= PredictImage(sess,img,skipPrediction,\n",
    "                      out_scores,out_boxes,out_classes)\n",
    "    img=cv2.resize(img, dsize=(800,500))\n",
    "\n",
    "    cv2.imshow(winName, img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    if cv2.getWindowProperty(winName,1) == -1 :\n",
    "        break\n",
    "    success,img = vidcap.read()\n",
    "    count=count+1\n",
    "    \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Camera Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(cv2.CAP_DSHOW)\n",
    "count = 0\n",
    "winName='Live Camera'\n",
    "skipPrediction=False\n",
    "out_scores=None\n",
    "out_boxes=None\n",
    "out_classes=None\n",
    "\n",
    "while True:\n",
    "    #time.sleep(5)\n",
    "    if (count%30!=0):  \n",
    "        skipPrediction=True\n",
    "    else:\n",
    "        skipPrediction=False\n",
    "           \n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    img = cv2.flip( frame, 1 ) \n",
    "    \n",
    "    img,out_scores,out_boxes,out_classes= PredictImage(sess,img,skipPrediction,\n",
    "                      out_scores,out_boxes,out_classes)\n",
    "    img=cv2.resize(img, dsize=(800,500))\n",
    "\n",
    "    cv2.imshow(winName, img)\n",
    "    count=count+1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    if cv2.getWindowProperty(winName,1) == -1 :\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "OMdut",
   "launcher_item_id": "bbBOL"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
